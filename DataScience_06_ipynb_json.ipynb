{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gukouk176-debug/colab2/blob/main/DataScience_06_ipynb_json.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqYqtiP9AUPe"
      },
      "source": [
        "# 第6回講義 データの前処理\n",
        "+ irisを使ったデータ処理\n",
        "+ タイタニックデータを用いたデータ処理\n",
        "+ breast-cancerのデータセットのデータ処理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEb6QWDxbPTp"
      },
      "source": [
        "# 全講義共通初期設定\n",
        "+ 警告の非表示(実装時は非推奨)\n",
        "+ numpy pandas小数点以下桁数の表示設定\n",
        "+ pandas全データ表示設定\n",
        "+ Google driveへの接続"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTEjZK-0AUPk"
      },
      "source": [
        "# ワーニングを非表示にする\n",
        "# この設定は不都合が見えなくなる為、お勧めしない\n",
        "# 今回は教育資料用に、出力を簡素化する為に利用する\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "# モジュールの読み込み\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# 小数点以下桁数の表示設定\n",
        "np.set_printoptions(precision = 3)\n",
        "pd.options.display.precision = 3\n",
        "\n",
        "# pandasの全データ表示設定\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-VDDmPSuWHh"
      },
      "source": [
        "#googledriveに接続\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8OgoRz32D8o"
      },
      "source": [
        "#google driveと接続できたかを確認\n",
        "!ls drive/MyDrive/DataScience"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lFp-LpvBL8A"
      },
      "source": [
        "# irisを使ったデータ処理\n",
        "\n",
        "Iris(アヤメのデータ)のデータセットを用いたデータ処理  \n",
        "ここでは以下の項目について演習を行う。  \n",
        "+ データの読み込み\n",
        "+ データの確認\n",
        "+ 欠損値の確認\n",
        "+ 説明変数・目的変数の設定\n",
        "+ データの分割（トレーニングデータ・テストデータ）\n",
        "+ モデルへの適用\n",
        "+ 結果の算出\n",
        "+ ダミー変数化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufkzKx_RAUPl"
      },
      "source": [
        "## データの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xUFK1LoAUPl"
      },
      "source": [
        "#ライブラリのインポートとirisデータの読み込み\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "##ライブラリpandasを使ったcsvデータの読み込み,sepで区切り記号を設定,もし日本語の場合,encodingを設定する必要があり\n",
        "iris_df = pd.read_csv('/content/drive/MyDrive/DataScience/iris.csv',sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIKzl9QIAUPl"
      },
      "source": [
        "## データの確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ucijuSXAUPn"
      },
      "source": [
        "# 先頭の10行だけ表示したい場合\n",
        "print(iris_df.head(10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rH4vWGT2AUPn"
      },
      "source": [
        "# 最後の5行だけ表示したい場合\n",
        "print(iris_df.tail())\n",
        "\n",
        "#データセットの項目のデータ型を確認\n",
        "iris_df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj3hJqjXAUPn"
      },
      "source": [
        "#データセットの項目(列ラベルともいう)確認\n",
        "iris_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17wB9p1HAUPo"
      },
      "source": [
        "## 欠損値の確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hO_VQfhEAUPo"
      },
      "source": [
        "#データセットの情報の表示（各項目の欠損でないデータ数、型など）\n",
        "print(iris_df.info())\n",
        "print()\n",
        "\n",
        "#各項目の欠損値数の表示\n",
        "print(iris_df.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUBsJjKdAUPo"
      },
      "source": [
        "#欠損値の確認、Falseなら欠損値ではない。Trueなら欠損値\n",
        "print(iris_df.head().isnull())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHzeOl6dAUPo"
      },
      "source": [
        "## 説明変数・目的変数の設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnfbiVsYAUPp"
      },
      "source": [
        "#説明変数の設定\n",
        "#pandasのデータフレームのまま説明変数切り取り\n",
        "X = iris_df[['sepal.length', 'sepal.width', 'petal.length', 'petal.width']]\n",
        "#取り出し方 loc:ラベル（変数名）指定 ,iloc:番号指定\n",
        "#X = iris_df.iloc[:, [0,1,2,3]]\n",
        "#X = iris_df.loc[:, ['sepal.length','sepal.width','petal.length','petal.width']]\n",
        "\n",
        "#目的変数の設定\n",
        "y = iris_df[['species']]\n",
        "# y = iris_df.iloc[:,[4]]\n",
        "# y = iris_df.loc[:, ['species']]\n",
        "\n",
        "#データフレームをarrayに変換,scikit-learnを使うときに必要\n",
        "#X = iris_df.iloc[:, [0,1,2,3]].values\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOQa7TOqAUPp"
      },
      "source": [
        "## データの分割と標準化\n",
        "トレーニングデータ・テストデータ\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q360jRdUAUPp"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# トレーニングデータとテストデータに分割:トレーニングデータ70%、テストデータ30%\n",
        "# 乱数を制御するパラメータ random_state は None にすると毎回異なるデータを生成する\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=None )\n",
        "\n",
        "# データの標準化処理 元データを平均0、標準偏差が1のものに変換する正規化法のこと\n",
        "#インスタンス生成\n",
        "sc = StandardScaler()\n",
        "\n",
        "#モデルへのフィット\n",
        "sc.fit(X_train)\n",
        "\n",
        "#トレーニングデータとテストデータの標準化処理\n",
        "X_train_std = sc.transform(X_train)\n",
        "X_test_std = sc.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHsVLpqSAUPp"
      },
      "source": [
        "## モデルへの適用 ・ 結果の算出"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFyU63RaAUPq"
      },
      "source": [
        "#決定木による学習\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#モデルのインスタンス生成\n",
        "tree_model = tree.DecisionTreeClassifier(max_depth=3)\n",
        "\n",
        "#学習\n",
        "tree_model.fit(X_train_std,y_train)\n",
        "\n",
        "#テストデータの適用\n",
        "predicted = tree_model.predict(X_test_std)\n",
        "\n",
        "#結果の表示\n",
        "print('正解率：',accuracy_score(y_test, predicted))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#トレーニングデータによるフィッティング結果とテストデータによる学習モデルの精度の検証\n",
        "print('正解率（train):  {:.4f}'.format(tree_model.score(X_train_std, y_train)))\n",
        "print('正解率（test):  {:.4f}'.format(tree_model.score(X_test_std, y_test)))"
      ],
      "metadata": {
        "id": "iyLoHcDRRTWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZ374g6-AUPq"
      },
      "source": [
        "## ダミー変数化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02BVDh1PAUPq"
      },
      "source": [
        "#pandasのデータフレームをarray配列化\n",
        "from sklearn import preprocessing\n",
        "X = iris_df[['sepal.length', 'sepal.width', 'petal.length', 'petal.width']]\n",
        "\n",
        "print(X.head())\n",
        "print()\n",
        "# DATA =X.as_matrix() # ← 旧表記方法で、Python3.7以降は 警告またはエラー表示\n",
        "DATA = X.values\n",
        "#DATA = X.values.tolist()\n",
        "\n",
        "print(DATA)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GQXwtzpAUPq"
      },
      "source": [
        "#ダミー変数化\n",
        "y_dummy = pd.get_dummies(y)  #, drop_first=True)\n",
        "\n",
        "print(y_dummy.head())\n",
        "# ダミー変数の結合\n",
        "y2 = pd.merge(y, y_dummy, left_index=True, right_index=True)\n",
        "#y2 = y.join(y_dummy)\n",
        "\n",
        "print(y2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKJf8d42RToK"
      },
      "source": [
        "## 順序尺度の数値化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuy-x9RFAUPr"
      },
      "source": [
        "#順序尺度の数値化\n",
        "size_mapping = {'Virginica': 2, 'Versicolor': 1, 'Setosa': 0}\n",
        "y3 = y['species'].map(size_mapping)\n",
        "\n",
        "print(y3.head())\n",
        "print(y3.tail())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i5nkU-PAUPr"
      },
      "source": [
        "#名義尺度の数値化 LabelEncoderは、ラベルを0～クラスの種類数n-1の値に変換してくれる、今回は3つのラベルを0,1,2\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "#LabelEncoderのインスタンスを生成\n",
        "le = LabelEncoder()\n",
        "#ラベルを覚えさせる\n",
        "le = le.fit(y)\n",
        "\n",
        "#ラベルを整数に変換\n",
        "y_encoded = le.transform(y)\n",
        "\n",
        "print(y_encoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nK4YHGe4RyqE"
      },
      "source": [
        "## 回帰による学習と評価"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5G2mR_WpAUPr"
      },
      "source": [
        "#回帰による学習とダミー変数,評価は平均二乗誤差 (MSE)と決定係数\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "#トレーニングデータとテストデータに分割\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y3, test_size=0.2, random_state=None )\n",
        "\n",
        "#インスタンス生成\n",
        "sc = StandardScaler()\n",
        "\n",
        "#モデルへのフィット\n",
        "sc.fit(X_train2)\n",
        "\n",
        "X_train_std2 = sc.transform(X_train2)\n",
        "X_test_std2 = sc.transform(X_test2)\n",
        "\n",
        "#モデルのインスタンス生成と学習(標準化あり)\n",
        "lr = linear_model.LinearRegression()\n",
        "lr.fit(X_train_std2, y_train2)\n",
        "\n",
        "predicted2 = lr.predict(X_test_std2)\n",
        "\n",
        "print('平均二乗誤差 (MSE)',mean_squared_error(y_test2, predicted2))\n",
        "print('決定係数 (R2)',r2_score(y_test2, predicted2))\n",
        "\n",
        "#モデルのインスタンス生成と学習(標準化なし)\n",
        "lr = linear_model.LinearRegression()\n",
        "lr.fit(X_train2,y_train2)\n",
        "\n",
        "predicted2 = lr.predict(X_test2)\n",
        "\n",
        "print('平均二乗誤差 (MSE)',mean_squared_error(y_test2, predicted2))\n",
        "print('決定係数 (R2)',r2_score(y_test2, predicted2))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUgd4oBwAUPr"
      },
      "source": [
        "#小数のまるめ(偶数への丸めであることに注意)\n",
        "b = np.round(X_train_std2, 2)\n",
        "\n",
        "#小数の丸める前\n",
        "print(X_train_std2[0])\n",
        "#小数の丸め後\n",
        "print(b[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFFCF1AFAUPs"
      },
      "source": [
        "# タイタニックデータを用いたデータ処理\n",
        "\n",
        "ここでは主に欠損値と説明変数の選択について学習する  \n",
        "+ 欠損値の確認\n",
        "+ 欠損値の補間（穴埋め）\n",
        "+ 説明変数を選択"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNEuuP51AUPs"
      },
      "source": [
        "#タイタニックデータの読み込み\n",
        "import pandas as pd\n",
        "\n",
        "titanic_df = pd.read_csv('/content/drive/MyDrive/DataScience/titanic_train.csv',sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Bq0FmuIAUPs"
      },
      "source": [
        "## 欠損値の確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFwrU522AUPs"
      },
      "source": [
        "#データの情報表示\n",
        "print(titanic_df.info())\n",
        "print()\n",
        "#各項目の欠損値数の表示\n",
        "print(titanic_df.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEne4g5QAUPs"
      },
      "source": [
        "titanic_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmB43uRkAUPt"
      },
      "source": [
        "## 欠損値の補間（穴埋め）\n",
        "### 欠損値の基本的な処理方法 : dropna()とfillna()を使う  \n",
        "+ 欠損値NaN（Not a Number，非数）がひとつでも含まれている行を削除する  \n",
        "`titanic_df.dropna()`\n",
        "\n",
        "+ ある行の指定された項目のすべての値が欠損していたら、その行を削除する  \n",
        "`titanic_df.dropna(subset=['Age','Cabin'], how='all')`\n",
        "\n",
        "+ すべての欠損値を0で置換する  \n",
        "`titanic_df.fillna(0)`\n",
        "\n",
        "+ すべての欠損値を平均で置換する、※数値型のみ  \n",
        "`titanic_df.fillna(data2.mean())`\n",
        "\n",
        "+ method = ‘ffill’を使って欠損値を直前の値で補完する数値型にのみ  \n",
        "`titanic_df.fillna(method = 'ffill')`\n",
        "\n",
        "+ １次の多項式で補完する。非数値型、前後に値のないデータには動作しない。  \n",
        "`titanic_df.interpolate(method='polynomial',order=1)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6nt374IAUPt"
      },
      "source": [
        "# 欠損値がひとつでも含まれている行を削除する\n",
        "titanic_df_drop1 = titanic_df.dropna()\n",
        "\n",
        "#データの情報表示\n",
        "print(titanic_df_drop1.info())\n",
        "print()                      # 空行の出力で改行\n",
        "\n",
        "#各項目の欠損値数の表示\n",
        "print(titanic_df_drop1.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9uj3SQ1AUPt"
      },
      "source": [
        "## 説明変数を選択"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbCRi-8SAUPt"
      },
      "source": [
        "# ある行の指定された項目のすべての値が欠損していたら、その行を削除する all.\n",
        "\n",
        "#引数how='any'を指定すると，欠損値が一つでも含まれる行が削除される\n",
        "#デフォルトがhow='any'なので、何も指定しないとこの動作になる\n",
        "titanic_df_drop2 = titanic_df.dropna(subset=['Age','Cabin'], how='any')\n",
        "\n",
        "# titanic_df_drop2 = titanic_df.dropna(subset=['Age','Cabin'])\n",
        "# ↑ デフォルトがhow='any'の為、上のコードと同等\n",
        "\n",
        "#データの情報表示\n",
        "print(titanic_df_drop2.info())\n",
        "print()\n",
        "\n",
        "#各項目の欠損値数の表示\n",
        "print(titanic_df_drop2.isnull().sum())\n",
        "print()\n",
        "#titanic_df_drop2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8vXI4U-AUPu"
      },
      "source": [
        "#すべての欠損値を0で置換する\n",
        "titanic_df_fill1 = titanic_df.fillna(0)\n",
        "\n",
        "#データの情報表示\n",
        "print(titanic_df_fill1.info())\n",
        "print()\n",
        "\n",
        "#各項目の欠損値数の表示\n",
        "print(titanic_df_fill1.isnull().sum())\n",
        "print()\n",
        "titanic_df_fill1.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d91SyTL-AUPu"
      },
      "source": [
        "#すべての欠損値を平均で置換する、※数値型のみ\n",
        "titanic_df_fill2 = titanic_df.fillna(titanic_df.mean())\n",
        "\n",
        "#データの情報表示\n",
        "print(titanic_df_fill2.info())\n",
        "print()\n",
        "#各項目の欠損値数の表示\n",
        "print(titanic_df_fill2.isnull().sum())\n",
        "print()\n",
        "titanic_df_fill2.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7h-oSfzAUPu"
      },
      "source": [
        "#説明変数と目的変数の選択\n",
        "\n",
        "#取り出し方 loc:ラベル（変数名）指定 ,iloc:番号指定\n",
        "Titanic_X = titanic_df.iloc[:, [2,5,9]]\n",
        "#X = titanic_df.loc[:, ['Age','Fare','Pclass']]\n",
        "\n",
        "#目的変数の設定\n",
        "Titanic_y = titanic_df.iloc[:,[1]]\n",
        "#.loc[:, ['Survived']]\n",
        "\n",
        "Titanic_X.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_H_MdtZsAUPv"
      },
      "source": [
        "#すべての欠損値を平均で置換する、※数値型のみ\n",
        "Titanic_X_fill = Titanic_X.fillna(Titanic_X.mean())\n",
        "Titanic_X_fill.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wsc0gH-bAUPv"
      },
      "source": [
        "#トレーニングデータとテストデータに分割\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(Titanic_X_fill, Titanic_y, test_size=0.2, random_state=None )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4OSfyLOAUPv"
      },
      "source": [
        "#決定木による学習\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#モデルのインスタンス生成\n",
        "tree_model = tree.DecisionTreeClassifier(max_depth=3)\n",
        "\n",
        "#学習\n",
        "tree_model.fit(X_train,y_train)\n",
        "\n",
        "#トレーニングデータによるフィッティング結果とテストデータによる学習モデルの精度の検証\n",
        "print('正解率（train):  {:.4f}'.format(tree_model.score(X_train, y_train)))\n",
        "print('正解率（test):  {:.4f}'.format(tree_model.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHxSezYLAUPw"
      },
      "source": [
        "## sklearnによるデータ処理例,標準化処理\n",
        "+ 平均値を０，標準偏差を１とする"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vehVA0AhAUPw"
      },
      "source": [
        "#sklearnによるデータ処理例,標準化処理\n",
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "X_train = np.array([[10.5, 0.3],[ 0.2, 0.4],[100, 40.4],[0.1, 0.1],[1000.5, 20.2]])\n",
        "X_scaled = preprocessing.scale(X_train)\n",
        "\n",
        "print(X_scaled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ag7rSLQ6AUPw"
      },
      "source": [
        "# breast-cancerのデータセット\n",
        "\n",
        "欠損値に文字が挿入されているときの処理方法についての学習  \n",
        "文字の入れ替えについて学習する。  \n",
        "Class（病気の重症度）を目的変数として推定を行う。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdsFoDWlAUPw"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "#csvファイルの読み込み\n",
        "bc_df = pd.read_csv('/content/drive/MyDrive/DataScience/breast-cancer-wisconsin.csv',sep=',')\n",
        "bc_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4H0rgGhAUPx"
      },
      "source": [
        "bc_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I61erkv3AUPx"
      },
      "source": [
        "bc_df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nr5g-EUeAUPx"
      },
      "source": [
        "#列ラベル（項目）に属する要素を抽出する．「？」が存在するのが確認できる\n",
        "#データフレームの中の指定した列の値をユニーク，重複のないデータにする\n",
        "print(bc_df[\"Bare Nuclei\"].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwRar0T9AUPx"
      },
      "source": [
        "#ラベル（項目）に属する要素の数を調べる．？が16個存在しているのがわかる\n",
        "print(bc_df[\"Bare Nuclei\"].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4OYUGLuAUPx"
      },
      "source": [
        "#？を別の文字に入れ替え：replace\n",
        "bc_df2 = bc_df.replace(\"?\", \"5\")\n",
        "#情報を確認：ただし、Bare Nucleiのデータ型はobjectのまま\n",
        "bc_df2.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzEpc_LtAUPy"
      },
      "source": [
        "#型の変換(列の指定)\n",
        "bc_df2 = bc_df2.astype({'Bare Nuclei':'int64'})\n",
        "#型の変換（全ての列をまとめて変換する場合）\n",
        "#bc_df2 = bc_df2.astype('int64')\n",
        "#データの確認\n",
        "bc_df2.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtHgA0tGAUPy"
      },
      "source": [
        "bc_df2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "St2TeRzaAUPy"
      },
      "source": [
        "#説明変数と目的変数の選択\n",
        "\n",
        "#取り出し方 loc:ラベル（変数名）指定 ,iloc:番号指定\n",
        "BC_X = bc_df2.iloc[:, [1,2,3,4,5,6,7,8,9]]\n",
        "#X = data2.loc[:, ['Age','Fare','Pclass']]\n",
        "\n",
        "#目的変数の設定\n",
        "BC_Y = bc_df2.iloc[:,[10]]\n",
        "#.loc[:, ['Survived']]\n",
        "\n",
        "BC_X.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCySSR2TQQFV"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}